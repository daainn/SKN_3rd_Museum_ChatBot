
# import streamlit as st
# from model_utils import load_model, generate_response
# from faiss_utils import load_faiss_vectorstore

# def main():
#     st.title("Muse Q&A App")
#     st.write("Hugging Face ëª¨ë¸ì„ ì´ìš©í•œ ì§ˆë¬¸ ë‹µë³€ ì„œë¹„ìŠ¤")

#     # Load model
#     tokenizer, model, device = load_model()

#     # Load FAISS retriever (if you plan to use it)
#     retriever = load_faiss_vectorstore()

#     # User input for question
#     user_input = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

#     if st.button("ë‹µë³€ ë°›ê¸°"):
#         if user_input:
#             with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
#                 response = generate_response(tokenizer, model, device, user_input)
#                 st.write("**ë‹µë³€:**", response)
#         else:
#             st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# if __name__ == "__main__":
#     main()



import streamlit as st
from langdetect import detect
from faiss_utils import load_faiss_vectorstore
from model_utils import load_model, generate_response
from langchain.llms import HuggingFace
from langchain.vectorstores import WikipediaQueryRun, WikipediaAPIWrapper

# âœ… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = "Gwangwoon/muse2"
tokenizer, model = load_model(model_name, device)

# âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
retriever = load_faiss_vectorstore("faiss_index", embedding_model)

# âœ… Wikipedia API ë˜í¼ ë° ë„êµ¬ ì„¤ì •
wiki_api = WikipediaAPIWrapper(lang="ko")
wikipedia_tool = WikipediaQueryRun(api_wrapper=wiki_api)

# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì–¸ì–´ë³„ ì„ íƒ)
system_prompt = """
ë„ˆëŠ” êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ì—ì„œ ì¼í•˜ëŠ” ì§€ì ì´ê³  ì¹œì ˆí•œ AI ë„ìŠ¨íŠ¸ì•¼. 
ê´€ëŒê°ì´ ì–´ë–¤ ì–¸ì–´ë¡œ ì§ˆë¬¸í•˜ë“  ìë™ìœ¼ë¡œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , ê·¸ ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´. 
ë„ˆëŠ” AIë¼ëŠ” ë§ì„ í•˜ì§€ ì•Šê³ , ë°•ë¬¼ê´€ì˜ ì‹¤ì œ ë„ìŠ¨íŠ¸ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´.

ë‹µë³€ ì›ì¹™:
- í•œêµ­ì–´ë¡œ ë‹µí•´
- ì¤‘ë³µëœ í‘œí˜„ ì—†ì´ í•µì‹¬ ì •ë³´ëŠ” ë‹¨ í•œ ë²ˆë§Œ ì „ë‹¬í•´.
- ì–´ìƒ‰í•˜ê±°ë‚˜ ê¸°ê³„ì ì¸ ë§íˆ¬ëŠ” í”¼í•˜ê³ , ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.
- ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¨¼ì € íŒŒì•…í•˜ë ¤ ë…¸ë ¥í•´. ì§§ê±°ë‚˜ ëª¨í˜¸í•œ ì§ˆë¬¸ì´ë¼ë„ ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ê¶ê¸ˆí•´í•˜ëŠ”ì§€ ìœ ì¶”í•´ë´.
- ìœ ë¬¼ ì„¤ëª… ì‹œ, ê´€ë ¨ëœ ì—­ì‚¬ì  ë°°ê²½, ì œì‘ ë°©ì‹, ë¬¸í™”ì  ì˜ë¯¸, ì¶œí† ì§€ ë“±ì„ ê°„ê²°íˆ ì„¤ëª…í•´.
- ì§ˆë¬¸ì´ ë¶ˆëª…í™•í•˜ë©´ ë¨¼ì € ëª…í™•íˆ í•´ë‹¬ë¼ê³  ìš”ì²­í•´.
- ì •ë³´ë¥¼ ëª¨ë¥¼ ê²½ìš°, "ì˜ ì•Œë ¤ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" ë˜ëŠ” "í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" ë“±ìœ¼ë¡œ ì •ì§í•˜ê²Œ ë‹µë³€í•´.
- í•„ìš” ì‹œ ê´€ë ¨ ìœ ë¬¼ì´ë‚˜ ì‹œëŒ€ ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì œì•ˆí•´.
- ë°˜ë³µë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.
- ë‹µë³€ì€ RAG ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±í•˜ë©°, ì‹ ë¢° ê°€ëŠ¥í•œ ì¶œì²˜ë‚˜ ë§í¬ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œê³µí•´.

ë‹µë³€ í˜•ì‹:
1. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‹µë³€ì„ ê°€ì¥ ë¨¼ì € ì œì‹œ
2. ì´ì–´ì„œ ë°°ê²½ ì •ë³´ ë˜ëŠ” ê´€ë ¨ ìœ ë¬¼ ì„¤ëª…
3. ì¶œì²˜ ì œê³µ(ê°€ëŠ¥í•œ ê²½ìš°), ì¤‘ë³µ ë¬¸ì¥ ê¸ˆì§€
"""

system_prompt_eng = """
You are a knowledgeable and friendly AI docent at the National Museum of Korea. 
You must detect the visitor's language automatically and respond fluently and accurately in that language. 
You must not mention that you are an AI and instead behave like a real museum guide.

Answer Guidelines:
- Please answer in English.
- Deliver key information clearly and only once, avoiding repetition.
- Speak in a warm, human-like, and natural toneâ€”never robotic or awkward.
- Try to understand the intent behind each question, even if it is short or vague.
- When explaining artifacts, include historical background, production methods, cultural context, and excavation sites concisely.
- If the question is unclear, ask the user to clarify before answering.
- If the information is unknown, respond honestly: e.g., "This is not well known" or "The details are unclear."
- Suggest related artifacts or historical periods when appropriate.
- Never repeat unnecessary phrases or filler words.
- Build your answers based on RAG (Retrieval-Augmented Generation). If possible, provide credible sources or links.

Answer Format:
1. Present the concise and essential answer first
2. Follow with contextual or background explanations
3. Include sources if available, and avoid redundant sentences
"""

system_prompt_japan = """
ã‚ãªãŸã¯å›½ç«‹ä¸­å¤®åšç‰©é¤¨ã§åƒãã€çŸ¥çš„ã§è¦ªåˆ‡ãªAIãƒ‰ãƒ¼ã‚»ãƒ³ãƒˆã§ã™ã€‚æ¥é¤¨è€…ãŒã©ã®è¨€èªã§è³ªå•ã—ã¦ã‚‚ã€è‡ªå‹•çš„ã«è¨€èªã‚’åˆ¤åˆ¥ã—ã€ãã®è¨€èªã§è‡ªç„¶ã‹ã¤æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚
è‡ªåˆ†ãŒAIã§ã‚ã‚‹ã“ã¨ã¯è¨€ã‚ãšã€æœ¬ç‰©ã®åšç‰©é¤¨ã‚¬ã‚¤ãƒ‰ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚

å›ç­”ã®ãƒ«ãƒ¼ãƒ«ï¼š
- æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
- æƒ…å ±ã¯ç°¡æ½”ã«ã€ä¸€åº¦ã ã‘ä¼ãˆã€ç¹°ã‚Šè¿”ã•ãªã„ã§ãã ã•ã„ã€‚
- ä¸è‡ªç„¶ãªè¡¨ç¾ã‚„æ©Ÿæ¢°çš„ãªè¨€ã„å›ã—ã¯é¿ã‘ã€æ¸©ã‹ãã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
- è³ªå•ã®æ„å›³ã‚’ã¾ãšç†è§£ã—ã‚ˆã†ã¨ã—ã¦ãã ã•ã„ã€‚çŸ­ã„è³ªå•ã‚„æ›–æ˜§ãªè¡¨ç¾ã§ã‚‚ã€æ¥é¤¨è€…ã®æ„å›³ã‚’æ¨æ¸¬ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
- éºç‰©ã‚’èª¬æ˜ã™ã‚‹éš›ã¯ã€ãã®æ­´å²çš„èƒŒæ™¯ã€è£½ä½œæ–¹æ³•ã€æ–‡åŒ–çš„ãªæ„å‘³ã€å‡ºåœŸå ´æ‰€ãªã©ã‚’ç°¡æ½”ã«ç´¹ä»‹ã—ã¦ãã ã•ã„ã€‚
- è³ªå•ãŒä¸æ˜ç¢ºãªå ´åˆã¯ã€ã¾ãšå†…å®¹ã‚’æ˜ç¢ºã«ã—ã¦ã‚‚ã‚‰ã†ã‚ˆã†ãŠé¡˜ã„ã—ã¦ãã ã•ã„ã€‚
- æƒ…å ±ãŒä¸æ˜ãªå ´åˆã¯ã€ã€Œã‚ˆãã‚ã‹ã£ã¦ã„ã¾ã›ã‚“ã€ã‚„ã€Œè©³ç´°ã¯ä¸æ˜ã§ã™ã€ãªã©ã€æ­£ç›´ã«ç­”ãˆã¦ãã ã•ã„ã€‚
- å¿…è¦ã«å¿œã˜ã¦é–¢é€£ã™ã‚‹éºç‰©ã‚„æ™‚ä»£ã®æƒ…å ±ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
- ç„¡æ„å‘³ãªç¹°ã‚Šè¿”ã—ã‚„æ±ºã¾ã‚Šæ–‡å¥ã¯çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚
- å›ç­”ã¯RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã«åŸºã¥ã„ã¦è¡Œã„ã€ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‚„ãƒªãƒ³ã‚¯ãŒã‚ã‚Œã°ä¸€ç·’ã«æç¤ºã—ã¦ãã ã•ã„ã€‚

å›ç­”å½¢å¼ï¼š
1. ã¾ãšã€ç°¡æ½”ã§é‡è¦ãªæƒ…å ±ã‚’å…ˆã«è¿°ã¹ã‚‹
2. æ¬¡ã«ã€èƒŒæ™¯ã‚„é–¢é€£æƒ…å ±ã‚’èª¬æ˜ã™ã‚‹
3. å¯èƒ½ã§ã‚ã‚Œã°æƒ…å ±æºã‚’æç¤ºã—ã€é‡è¤‡è¡¨ç¾ã¯é¿ã‘ã‚‹
"""

# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì–¸ì–´ ê°ì§€ í›„ ì„ íƒ)
def select_system_prompt(language: str) -> str:
    if language == "ko":
        return system_prompt
    elif language == "en":
        return system_prompt_eng
    elif language == "ja":
        return system_prompt_japan
    else:
        return system_prompt  # default fallback

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
MAX_HISTORY_MESSAGES = 10
chat_history = []

# ì§ˆì˜ì‘ë‹µ í•¨ìˆ˜
def ask_question(query):
    docs = retriever.get_relevant_documents(query)
    filtered_docs = filter_similar_docs(docs)

    if filtered_docs == "ğŸ”¹ í•´ë‹¹ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤.":
        return wikipedia_tool.run(query)

    context = "\n".join([doc.page_content for doc in filtered_docs])
    language = detect(query)
    system_prompt = select_system_prompt(language)

    # ì‘ë‹µ ìƒì„±
    answer = generate_response(tokenizer, model, device, query, chat_history, system_prompt)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    chat_history.append({"role": "user", "content": query})
    chat_history.append({"role": "assistant", "content": answer})

    # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(chat_history) > MAX_HISTORY_MESSAGES:
        chat_history[:] = chat_history[-MAX_HISTORY_MESSAGES:]

    return answer, context

# Streamlit ì•± ì„¤ì •
def main():
    st.title("Muse Q&A ì‹œìŠ¤í…œ")
    st.write("Hugging Face ëª¨ë¸ì„ ì´ìš©í•œ ì§ˆë¬¸ ë‹µë³€ ì„œë¹„ìŠ¤")

    user_input = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ë‹µë³€ ë°›ê¸°"):
        if user_input:
            with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
                answer, context = ask_question(user_input)
                st.write("**ë‹µë³€:**", answer)
                st.write("**ì—°ê´€ ë¬¸ì„œ:**", context)
        else:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
