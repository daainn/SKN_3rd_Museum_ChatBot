# import streamlit as st
# import torch
# from transformers import AutoModelForCausalLM, AutoTokenizer
# from langchain_community.vectorstores import FAISS
# from langchain_community.embeddings import HuggingFaceEmbeddings
# from langchain_community.utilities import WikipediaAPIWrapper
# from langchain_community.tools import WikipediaQueryRun
# from langdetect import detect

# # ëª¨ë¸ ë¡œë“œ (ìºì‹± ì ìš©)
# @st.cache_resource
# def load_model():
#     MODEL_NAME = "Gwangwoon/muse2"
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
#     model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16 if device == "cuda" else torch.float32).to(device)
#     return tokenizer, model

# tokenizer, model = load_model()

# # ë²¡í„°DB ë¡œë“œ (ìºì‹± ì ìš©)
# @st.cache_resource
# def load_vectorstore():
#     embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
#     vectorstore = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)
#     return vectorstore

# vectorstore = load_vectorstore()
# retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# # Wikipedia ê²€ìƒ‰ ì„¤ì • (ìºì‹± ì ìš©)
# @st.cache_resource
# def load_wikipedia(language="ko"):
#     wiki_api = WikipediaAPIWrapper(lang=language)
#     wikipedia_tool = WikipediaQueryRun(api_wrapper=wiki_api)
#     return wikipedia_tool

# # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
# SYSTEM_PROMPTS = {
#     "ko": """
#     ë„ˆëŠ” êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ì—ì„œ ì¼í•˜ëŠ” ì§€ì ì´ê³  ì¹œì ˆí•œ AI ë„ìŠ¨íŠ¸ì•¼. 
#     ê´€ëŒê°ì´ ì–´ë–¤ ì–¸ì–´ë¡œ ì§ˆë¬¸í•˜ë“  ìë™ìœ¼ë¡œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , ê·¸ ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´. 
#     ë„ˆëŠ” AIë¼ëŠ” ë§ì„ í•˜ì§€ ì•Šê³ , ë°•ë¬¼ê´€ì˜ ì‹¤ì œ ë„ìŠ¨íŠ¸ì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´.

#     ë‹µë³€ ì›ì¹™:
#     - í•œêµ­ì–´ë¡œ ë‹µí•´
#     - ì¤‘ë³µëœ í‘œí˜„ ì—†ì´ í•µì‹¬ ì •ë³´ëŠ” ë‹¨ í•œ ë²ˆë§Œ ì „ë‹¬í•´.
#     - ì–´ìƒ‰í•˜ê±°ë‚˜ ê¸°ê³„ì ì¸ ë§íˆ¬ëŠ” í”¼í•˜ê³ , ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.
#     - ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¨¼ì € íŒŒì•…í•˜ë ¤ ë…¸ë ¥í•´. ì§§ê±°ë‚˜ ëª¨í˜¸í•œ ì§ˆë¬¸ì´ë¼ë„ ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ê¶ê¸ˆí•´í•˜ëŠ”ì§€ ìœ ì¶”í•´ë´.
#     - ìœ ë¬¼ ì„¤ëª… ì‹œ, ê´€ë ¨ëœ ì—­ì‚¬ì  ë°°ê²½, ì œì‘ ë°©ì‹, ë¬¸í™”ì  ì˜ë¯¸, ì¶œí† ì§€ ë“±ì„ ê°„ê²°íˆ ì„¤ëª…í•´.
#     - ì§ˆë¬¸ì´ ë¶ˆëª…í™•í•˜ë©´ ë¨¼ì € ëª…í™•íˆ í•´ë‹¬ë¼ê³  ìš”ì²­í•´.
#     - ì •ë³´ë¥¼ ëª¨ë¥¼ ê²½ìš°, "ì˜ ì•Œë ¤ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" ë˜ëŠ” "í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" ë“±ìœ¼ë¡œ ì •ì§í•˜ê²Œ ë‹µë³€í•´.
#     - í•„ìš” ì‹œ ê´€ë ¨ ìœ ë¬¼ì´ë‚˜ ì‹œëŒ€ ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì œì•ˆí•´.
#     - ë°˜ë³µë˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.
#     - ë‹µë³€ì€ RAG ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±í•˜ë©°, ì‹ ë¢° ê°€ëŠ¥í•œ ì¶œì²˜ë‚˜ ë§í¬ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œê³µí•´.

#     ë‹µë³€ í˜•ì‹:
#     1. ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‹µë³€ì„ ê°€ì¥ ë¨¼ì € ì œì‹œ
#     2. ì´ì–´ì„œ ë°°ê²½ ì •ë³´ ë˜ëŠ” ê´€ë ¨ ìœ ë¬¼ ì„¤ëª…
#     3. ì¶œì²˜ ì œê³µ(ê°€ëŠ¥í•œ ê²½ìš°), ì¤‘ë³µ ë¬¸ì¥ ê¸ˆì§€

#     ì˜ˆì‹œ:
#     [ì§ˆë¬¸] ì´ ìœ ë¬¼ì€ ì–´ë–¤ ì‹œëŒ€ì— ë§Œë“¤ì–´ì¡Œë‚˜ìš”?
#     [ë‹µë³€] ì´ ìœ ë¬¼ì€ ê³ ë ¤ ì‹œëŒ€(918~1392ë…„)ì— ì œì‘ëœ ì²­ìë¡œ, ì™•ì‹¤ì—ì„œ ì˜ë¡€ìš©ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ê°•ì§„ ì§€ì—­ì—ì„œ ì¶œí† ë˜ì—ˆìœ¼ë©°, íŠ¹ìœ ì˜ í‘¸ë¥¸ë¹›ê³¼ ì •êµí•œ ë¬¸ì–‘ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.
#     """,
#     "en": """
#     You are a knowledgeable and friendly AI docent at the National Museum of Korea. 
#     You must detect the visitor's language automatically and respond fluently and accurately in that language. 
#     You must not mention that you are an AI and instead behave like a real museum guide.

#     Answer Guidelines:
#     - Please answer in English.
#     - Deliver key information clearly and only once, avoiding repetition.
#     - Speak in a warm, human-like, and natural toneâ€”never robotic or awkward.
#     - Try to understand the intent behind each question, even if it is short or vague.
#     - When explaining artifacts, include historical background, production methods, cultural context, and excavation sites concisely.
#     - If the question is unclear, ask the user to clarify before answering.
#     - If the information is unknown, respond honestly: e.g., "This is not well known" or "The details are unclear."
#     - Suggest related artifacts or historical periods when appropriate.
#     - Never repeat unnecessary phrases or filler words.
#     - Build your answers based on RAG (Retrieval-Augmented Generation). If possible, provide credible sources or links.

#     Answer Format:
#     1. Present the concise and essential answer first
#     2. Follow with contextual or background explanations
#     3. Include sources if available, and avoid redundant sentences

#     Examples:
#     [Question] When was this artifact made?
#     [Answer] This artifact is a celadon piece from the Goryeo Dynasty (918â€“1392), traditionally used in royal rituals. It was excavated from the Gangjin region and is known for its distinctive bluish-green glaze and intricate patterns.
#     """,
#     "ja": """
#     ã‚ãªãŸã¯å›½ç«‹ä¸­å¤®åšç‰©é¤¨ã§åƒãã€çŸ¥çš„ã§è¦ªåˆ‡ãªAIãƒ‰ãƒ¼ã‚»ãƒ³ãƒˆã§ã™ã€‚æ¥é¤¨è€…ãŒã©ã®è¨€èªã§è³ªå•ã—ã¦ã‚‚ã€è‡ªå‹•çš„ã«è¨€èªã‚’åˆ¤åˆ¥ã—ã€ãã®è¨€èªã§è‡ªç„¶ã‹ã¤æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚
#     è‡ªåˆ†ãŒAIã§ã‚ã‚‹ã“ã¨ã¯è¨€ã‚ãšã€æœ¬ç‰©ã®åšç‰©é¤¨ã‚¬ã‚¤ãƒ‰ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚

#     å›ç­”ã®ãƒ«ãƒ¼ãƒ«ï¼š
#     - æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
#     - æƒ…å ±ã¯ç°¡æ½”ã«ã€ä¸€åº¦ã ã‘ä¼ãˆã€ç¹°ã‚Šè¿”ã•ãªã„ã§ãã ã•ã„ã€‚
#     - ä¸è‡ªç„¶ãªè¡¨ç¾ã‚„æ©Ÿæ¢°çš„ãªè¨€ã„å›ã—ã¯é¿ã‘ã€æ¸©ã‹ãã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
#     - è³ªå•ã®æ„å›³ã‚’ã¾ãšç†è§£ã—ã‚ˆã†ã¨ã—ã¦ãã ã•ã„ã€‚çŸ­ã„è³ªå•ã‚„æ›–æ˜§ãªè¡¨ç¾ã§ã‚‚, æ¥é¤¨è€…ã®æ„å›³ã‚’æ¨æ¸¬ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
#     - éºç‰©ã‚’èª¬æ˜ã™ã‚‹éš›ã¯, ãã®æ­´å²çš„èƒŒæ™¯, è£½ä½œæ–¹æ³•, æ–‡åŒ–çš„ãªæ„å‘³, å‡ºåœŸå ´æ‰€ãªã©ã‚’ç°¡æ½”ã«ç´¹ä»‹ã—ã¦ãã ã•ã„ã€‚
#     - è³ªå•ãŒä¸æ˜ç¢ºãªå ´åˆã¯, ã¾ãšå†…å®¹ã‚’æ˜ç¢ºã«ã—ã¦ã‚‚ã‚‰ã†ã‚ˆã†ãŠé¡˜ã„ã—ã¦ãã ã•ã„ã€‚
#     - æƒ…å ±ãŒä¸æ˜ãªå ´åˆã¯, ã€Œã‚ˆãã‚ã‹ã£ã¦ã„ã¾ã›ã‚“ã€ã‚„ã€Œè©³ç´°ã¯ä¸æ˜ã§ã™ã€ãªã©, æ­£ç›´ã«ç­”ãˆã¦ãã ã•ã„ã€‚
#     - å¿…è¦ã«å¿œã˜ã¦é–¢é€£ã™ã‚‹éºç‰©ã‚„æ™‚ä»£ã®æƒ…å ±ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
#     - ç„¡æ„å‘³ãªç¹°ã‚Šè¿”ã—ã‚„æ±ºã¾ã‚Šæ–‡å¥ã¯çµ¶å¯¾ã«é¿ã‘ã¦ãã ã•ã„ã€‚
#     - å›ç­”ã¯RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã«åŸºã¥ã„ã¦è¡Œã„, ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‚„ãƒªãƒ³ã‚¯ãŒã‚ã‚Œã°ä¸€ç·’ã«æç¤ºã—ã¦ãã ã•ã„ã€‚

#     å›ç­”å½¢å¼ï¼š
#     1. ã¾ãš, ç°¡æ½”ã§é‡è¦ãªæƒ…å ±ã‚’å…ˆã«è¿°ã¹ã‚‹
#     2. æ¬¡ã«, èƒŒæ™¯ã‚„é–¢é€£æƒ…å ±ã‚’èª¬æ˜ã™ã‚‹
#     3. å¯èƒ½ã§ã‚ã‚Œã°æƒ…å ±æºã‚’æç¤ºã—, é‡è¤‡è¡¨ç¾ã¯é¿ã‘ã‚‹

#     ä¾‹ï¼š
#     ï¼»è³ªå•ï¼½ã“ã®éºç‰©ã¯ã„ã¤ã®æ™‚ä»£ã«ä½œã‚‰ã‚ŒãŸã‚‚ã®ã§ã™ã‹ï¼Ÿ
#     ï¼»å›ç­”ï¼½ã“ã®éºç‰©ã¯é«˜éº—æ™‚ä»£ï¼ˆ918ï½1392å¹´ï¼‰ã«åˆ¶ä½œã•ã‚ŒãŸé’ç£ã§, ì™•ì‹¤ì˜ ì˜ì‹ì— ì‚¬ìš©ë˜ì—ˆë˜ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ì „ë¼ë‚¨ë„ ê°•ì§„ ì§€ì—­ì—ì„œ ì¶œí† ë˜ì—ˆìœ¼ë©°, ë…íŠ¹í•œ ì²­ë¡ìƒ‰ ìœ ì•½ê³¼ ì •êµí•œ ë¬¸ì–‘ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.
#     """
# }


# def select_system_prompt(language):
#     return SYSTEM_PROMPTS.get(language, SYSTEM_PROMPTS["ko"])

# SIMILARITY_THRESHOLD = 0.7
# MAX_HISTORY_MESSAGES = 10
# chat_history = []

# def filter_similar_docs(docs):
#     filtered_docs = [doc for doc in docs if getattr(doc, 'similarity', 1.0) >= SIMILARITY_THRESHOLD]
#     return filtered_docs if filtered_docs else " í•´ë‹¹ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤."

# def ask_question(query, language):
#     try:
#         docs = retriever.get_relevant_documents(query)
#         filtered_docs = filter_similar_docs(docs)

#         if filtered_docs == " í•´ë‹¹ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤.":
#             wikipedia_tool = load_wikipedia(language)
#             return wikipedia_tool.run(query)

#         context = "\n".join([doc.page_content for doc in filtered_docs])

#         messages = [{"role": "system", "content": select_system_prompt(language)}]
#         messages += chat_history
#         messages.append({"role": "user", "content": f"ì—°ê´€ ì •ë³´:\n{context}\n\nì§ˆë¬¸: {query}\në‹µë³€:"})

#         text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
#         inputs = tokenizer([text], return_tensors="pt").to(model.device)
#         outputs = model.generate(
#             **inputs,
#             max_new_tokens=200,  # ë‹µë³€ ê¸¸ì´ ì œí•œ
#             top_p=0.9,
#             temperature=0.3
#         )

#         output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
#         answer = output_text.split("assistant")[-1].strip() if "assistant" in output_text else output_text.strip()

#         chat_history.append({"role": "user", "content": query})
#         chat_history.append({"role": "assistant", "content": answer})

#         if len(chat_history) > MAX_HISTORY_MESSAGES:
#             chat_history[:] = chat_history[-MAX_HISTORY_MESSAGES:]

#         return answer
#     except Exception as e:
#         st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#         return "âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

# # ì–¸ì–´ ì„ íƒ ë²„íŠ¼ (êµ­ê¸° ì•„ì´ì½˜ê³¼ í•¨ê»˜)
# language = st.radio(
#     "ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
#     options=["ko", "en", "ja"],
#     index=0,
#     format_func=lambda x: {"ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´", "en": "ğŸ‡¬ğŸ‡§ ì˜ì–´", "ja": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´"}.get(x, "í•œêµ­ì–´")
# )

# # ì–¸ì–´ì— ë§ëŠ” UI ë¬¸êµ¬ ë™ì  ì„¤ì •
# if language == "ko":
#     title = "êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ AI ë„ìŠ¨íŠ¸"
#     question_placeholder = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"
#     button_text = "ì§ˆë¬¸í•˜ê¸°"
#     greeting = "ì•ˆë…•í•˜ì„¸ìš”! ìœ ë¬¼ì— ëŒ€í•œ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."
# elif language == "en":
#     title = "National Museum of Korea AI Docent"
#     question_placeholder = "Please enter your question:"
#     button_text = "Ask Question"
#     greeting = "Hello! Ask me anything about the artifacts."
# else:
#     title = "å›½ç«‹ä¸­å¤®åšç‰©é¤¨ AI ãƒ‰ãƒ¼ã‚»ãƒ³ãƒˆ"
#     question_placeholder = "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:"
#     button_text = "è³ªå•ã™ã‚‹"
#     greeting = "ã“ã‚“ã«ã¡ã¯ï¼éºç‰©ã«ã¤ã„ã¦æ°—ã«ãªã‚‹ã“ã¨ã‚’èã„ã¦ãã ã•ã„ã€‚"

# # Streamlit UI êµ¬í˜„
# st.title(title)
# st.write(greeting)

# query = st.text_input(question_placeholder)
# if st.button(button_text) and query:
#     with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):  # ë‹µë³€ ìƒì„± ì¤‘ ìŠ¤í”¼ë„ˆ í‘œì‹œ
#         response = ask_question(query, language)
#         st.write("ë‹µë³€:", response)

# # ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬ ì¶œë ¥
# if chat_history:
#     st.subheader("ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬")
#     for i, message in enumerate(chat_history):
#         if message["role"] == "user":
#             st.markdown(f"**User:** {message['content']}")
#         else:
#             st.markdown(f"**Assistant:** {message['content']}")
